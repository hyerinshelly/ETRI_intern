{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UP/DOWN prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Betting(gym.Env):\n",
    "\n",
    "    # actions available\n",
    "    UP = 0\n",
    "    DOWN = 1\n",
    "\n",
    "    def __init__(self, data):\n",
    "        super(Betting, self).__init__() # gym.Env의 __init__ 호출\n",
    "\n",
    "        # data 정의\n",
    "        self.data = data\n",
    "        self.size = len(data) # size of the data\n",
    "        self.range = 10  # range of the data\n",
    "\n",
    "        # randomly assign the inital location of agent\n",
    "        self.observe_idx = np.random.randint(self.size - 1)\n",
    "        self.agent_position = data[self.observe_idx]\n",
    "\n",
    "        # respective actions of agents : up, down\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "\n",
    "        # set the observation space to (1,) to represent agent position\n",
    "        self.observation_space = spaces.Box(low=0, high=self.range, shape=(1,), dtype=np.uint8)\n",
    "\n",
    "    def step(self, action):\n",
    "        info = {}  # additional information\n",
    "\n",
    "        reward = 0\n",
    "\n",
    "        # UP, DOWN 맞으면 reward=1, 틀리면 맞을 때까지 반복\n",
    "        if action == self.UP:\n",
    "            if self.data[self.observe_idx] < self.data[self.observe_idx + 1]:\n",
    "                reward += 1\n",
    "                self.observe_idx += 1\n",
    "            else:\n",
    "                reward += 0\n",
    "        elif action == self.DOWN:\n",
    "            if self.data[self.observe_idx] > self.data[self.observe_idx + 1]:\n",
    "                reward += 1\n",
    "                self.observe_idx += 1\n",
    "            else:\n",
    "                reward += 0\n",
    " #       else:\n",
    " #           raise ValueError(\"Received invalid action={} which is not part of the action space\".format(action))\n",
    "\n",
    "        # 더 이상 데이터가 없을 경우, done\n",
    "        done = bool(self.observe_idx == self.size - 1)\n",
    "        \n",
    "        if not done:\n",
    "            self.agent_position = data[self.observe_idx]\n",
    "\n",
    "        return np.array([self.agent_position]).astype(np.uint8), reward, done, info\n",
    "\n",
    "    def render(self, mode='console'):\n",
    "        '''\n",
    "            render the state\n",
    "        '''\n",
    "#         if mode != 'console':\n",
    "#             raise NotImplementedError()\n",
    "\n",
    "#         for pos in range(self.size):\n",
    "#             if pos == self.agent_position:\n",
    "#                 print(\"X\", end='')\n",
    "#             else:\n",
    "#                 print('.', end='')\n",
    "#             print('')\n",
    "\n",
    "    def reset(self):\n",
    "        # -1 to ensure agent inital position will not be at the end state\n",
    "        self.observe_idx = np.random.randint(self.size - 2)\n",
    "        self.agent_position = data[self.observe_idx]\n",
    "\n",
    "        return np.array([self.agent_position]).astype(np.uint8)\n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is to test if custom enviroment created properly\n",
    "# If the environment don't follow the gym interface, an error will be thrown\n",
    "\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "\n",
    "data = [0,9,7,4,3,5]\n",
    "\n",
    "env = Betting(data)\n",
    "check_env(env, warn=True)\n",
    "\n",
    "# try draw the grid world\n",
    "obs = env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a DummyVecEnv.\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:58: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:67: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/stable_baselines/common/policies.py:115: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/stable_baselines/common/policies.py:560: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/stable_baselines/a2c/utils.py:156: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/stable_baselines/common/distributions.py:326: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/stable_baselines/common/distributions.py:327: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:313: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:313: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/stable_baselines/acktr/acktr.py:175: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/stable_baselines/acktr/acktr.py:180: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/stable_baselines/acktr/kfac.py:99: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/stable_baselines/acktr/kfac.py:298: The name tf.diag is deprecated. Please use tf.linalg.tensor_diag instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/stable_baselines/acktr/kfac.py:546: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/stable_baselines/acktr/kfac.py:548: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/stable_baselines/acktr/acktr.py:220: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/stable_baselines/acktr/acktr.py:222: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/stable_baselines/acktr/acktr.py:304: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/stable_baselines/acktr/acktr.py:305: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/stable_baselines/acktr/kfac.py:973: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/stable_baselines/acktr/kfac.py:914: The name tf.mod is deprecated. Please use tf.math.mod instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/stable_baselines/acktr/kfac.py:621: The name tf.self_adjoint_eig is deprecated. Please use tf.linalg.eigh instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/iot/anaconda3/envs/tf115/lib/python3.7/site-packages/stable_baselines/acktr/acktr.py:317: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "---------------------------------\n",
      "| explained_variance | -0.289   |\n",
      "| fps                | 43       |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 0.693    |\n",
      "| policy_loss        | 1.43     |\n",
      "| total_timesteps    | 0        |\n",
      "| value_loss         | 6.75     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| explained_variance | 0         |\n",
      "| fps                | 1390      |\n",
      "| nupdates           | 100       |\n",
      "| policy_entropy     | 0.0104    |\n",
      "| policy_loss        | -7.49e-05 |\n",
      "| total_timesteps    | 2079      |\n",
      "| value_loss         | 0.000563  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.956    |\n",
      "| fps                | 1638     |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 0.577    |\n",
      "| policy_loss        | -0.0182  |\n",
      "| total_timesteps    | 4179     |\n",
      "| value_loss         | 0.0554   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.962    |\n",
      "| fps                | 1734     |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 0.641    |\n",
      "| policy_loss        | -0.0286  |\n",
      "| total_timesteps    | 6279     |\n",
      "| value_loss         | 0.0381   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.99     |\n",
      "| fps                | 1785     |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 0.418    |\n",
      "| policy_loss        | -0.00256 |\n",
      "| total_timesteps    | 8379     |\n",
      "| value_loss         | 0.013    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.996    |\n",
      "| fps                | 1806     |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 0.404    |\n",
      "| policy_loss        | 0.00332  |\n",
      "| total_timesteps    | 10479    |\n",
      "| value_loss         | 0.00616  |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# import various RL algorithms\n",
    "from stable_baselines import DQN, PPO2, A2C, ACKTR\n",
    "\n",
    "# Train the agent\n",
    "model = ACKTR('MlpPolicy', env, verbose=1).learn(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "Action:  1\n",
      "obs= [4] reward= 1 done= False\n",
      "Step 2\n",
      "Action:  1\n",
      "obs= [3] reward= 1 done= False\n",
      "Step 3\n",
      "Action:  0\n",
      "obs= [3] reward= 1 done= True\n",
      "Goal reached! reward= 1\n"
     ]
    }
   ],
   "source": [
    "# running the simulation with trained model to verify result\n",
    "\n",
    "obs = env.reset()\n",
    "n_steps = 50\n",
    "for step in range(n_steps):\n",
    "  action, _ = model.predict(obs, deterministic=True)\n",
    "  print(\"Step {}\".format(step + 1))\n",
    "  print(\"Action: \", action)\n",
    "  obs, reward, done, info = env.step(action)\n",
    "  print('obs=', obs, 'reward=', reward, 'done=', done)\n",
    "  env.render(mode='console')\n",
    "  if done:\n",
    "    # Note that the VecEnv resets automatically\n",
    "    # when a done signal is encountered\n",
    "    print(\"Goal reached!\", \"reward=\", reward)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  :  0 , prob :  [0.990036   0.00996393]\n",
      "1  :  0 , prob :  [0.986093   0.01390699]\n",
      "2  :  0 , prob :  [0.93550116 0.06449886]\n",
      "3  :  0 , prob :  [0.66572607 0.33427387]\n",
      "4  :  1 , prob :  [0.24379683 0.7562032 ]\n",
      "5  :  1 , prob :  [0.07148959 0.9285104 ]\n",
      "6  :  1 , prob :  [0.02611539 0.97388464]\n",
      "7  :  1 , prob :  [0.01231219 0.98768777]\n",
      "8  :  1 , prob :  [0.00705826 0.99294174]\n",
      "9  :  1 , prob :  [0.00465138 0.99534863]\n"
     ]
    }
   ],
   "source": [
    "# print the trained policy map\n",
    "# recall UP = 0, DOWN = 1\n",
    "for i in range(10):\n",
    "    obs = [i]\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "\n",
    "    print(i, \" : \", action, \", prob : \", model.action_probability(obs), end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf115",
   "language": "python",
   "name": "tf115"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
